{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "425f424f98da7c22",
   "metadata": {},
   "source": [
    " 1) Download and read the \"data.csv\" dataset. Split the dataset in train and test set (use your choice of splitting). Train a linear regression model for predicting \"Apparent Temperature (C)\" and report the performance (use your choice of at least four performance metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b607fce6ffe2cfb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-24T09:26:36.808924075Z",
     "start_time": "2023-08-24T09:26:36.618726675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96453 entries, 0 to 96452\n",
      "Data columns (total 8 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Precip Type               95936 non-null  object \n",
      " 1   Temperature (C)           96453 non-null  float64\n",
      " 2   Apparent Temperature (C)  96453 non-null  float64\n",
      " 3   Humidity                  96453 non-null  float64\n",
      " 4   Wind Speed (km/h)         96453 non-null  float64\n",
      " 5   Wind Bearing (degrees)    96453 non-null  int64  \n",
      " 6   Visibility (km)           96453 non-null  float64\n",
      " 7   Pressure (millibars)      96453 non-null  float64\n",
      "dtypes: float64(6), int64(1), object(1)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataframe = pd.read_csv(\"data_6.csv\")\n",
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "579e4de89062c235",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-24T09:26:36.815454430Z",
     "start_time": "2023-08-24T09:26:36.811979205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array(['rain', 'snow', nan], dtype=object)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe[\"Precip Type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89180fa9a4c35221",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-24T09:26:39.388726215Z",
     "start_time": "2023-08-24T09:26:39.341418873Z"
    }
   },
   "outputs": [],
   "source": [
    "dataframe.dropna(subset=[\"Precip Type\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597723fdfd703073",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.isnull().values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e635b5795f46e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now that we have no more nulls to worry about, normalize our class.\n",
    "#prepare class:\n",
    "dataframe[\"Precip Type\"] = dataframe[\"Precip Type\"].map({'rain':0, 'snow':1})\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3fb1f6f391e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "dataframe[dataframe.columns.difference(['Precip Type'])] = StandardScaler().fit_transform(dataframe[dataframe.columns.difference(['Precip Type'])])\n",
    "dataframe.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429eec1b295f42e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets, keeping the proportion of label on a 80-20 prop.\n",
    "y = dataframe[\"Apparent Temperature (C)\"]\n",
    "X = dataframe[dataframe.columns.difference(['Precip Type', 'Apparent Temperature (C)'])]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split ( X, y, test_size=0.2, stratify=dataframe['Precip Type'], random_state = 13)\n",
    "# Show the proportion of each value in the 'Precip Type' column for the original dataframe\n",
    "# Check the proportion of 'Precip Type' in the original, training, and test data\n",
    "print(\"Original distribution:\")\n",
    "print(dataframe['Precip Type'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nTraining distribution:\")\n",
    "print(dataframe.loc[X_train.index, 'Precip Type'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nTest distribution:\")\n",
    "print(dataframe.loc[X_test.index, 'Precip Type'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0d1f46314c9db6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402614483490f569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, median_absolute_error\n",
    "\n",
    "lin = LinearRegression()\n",
    "lin.fit(X_train, y_train)\n",
    "y_pred = lin.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "median = median_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Print metrics to the screen\n",
    "\n",
    "print(f\"Median Absolute Error: {median:.5f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.5f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.5f}\")\n",
    "print(f\"R-squared (R2): {r2:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca6979640f16b5b",
   "metadata": {},
   "source": [
    " 2) Apply PCA on the dataset and select the first three principal components. Split the dataset into train and test using the same method used in Q1. Compare the performance of this model with the performance obtained in Q1.  Explain the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f44369d36b1388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X)\n",
    "X_PCA = pca.transform(X)\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split ( X_PCA, y, test_size=0.2, stratify=dataframe['Precip Type'], random_state = 13)\n",
    "\n",
    "\n",
    "lin_PCA = LinearRegression()\n",
    "lin_PCA.fit(X_train_pca, y_train_pca)\n",
    "y_pred_PCA = lin_PCA.predict(X_test_pca)\n",
    "\n",
    "mae_pca = mean_absolute_error(y_test_pca, y_pred_PCA)\n",
    "mse_pca = mean_squared_error(y_test_pca, y_pred_PCA)\n",
    "r2_pca = r2_score(y_test_pca, y_pred_PCA)\n",
    "median_pca = median_absolute_error(y_test_pca, y_pred_PCA)\n",
    "\n",
    "print(f\"Median Absolute Error: {median_pca:.5f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_pca:.5f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_pca:.5f}\")\n",
    "print(f\"R-squared (R2): {r2_pca:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5abebc52f84d692",
   "metadata": {},
   "source": [
    "We can see quite a decrease on the model quality when we perform a PCA to only 3 features. The reason for that is the decrease of variance caused by the feature decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef1be80934c967a",
   "metadata": {},
   "source": [
    " 3) Load \"data.csv \" datasets  and follow this link for the data description (features ['Temperature (C)','Humidity','Wind Speed (km/h)','Wind Bearing (degrees)','Visibility (km)','Pressure (millibars)'] and Precip Type as target). Apply PCA on the dataset and select the first three principal components. Split the dataset in train and test set (use your choice of splitting). Train a logistic regression model and report the performance (use your choice of at least 4 performance metric)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7891ad23906b5a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_2 = pd.read_csv(\"data_6.csv\")\n",
    "dataframe_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d174396337e41de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_2.dropna(subset=[\"Precip Type\"], inplace=True)\n",
    "dataframe_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1643636a40907a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "filtered_dataframe = dataframe_2.drop(columns={'Apparent Temperature (C)'}, axis=1)\n",
    "filtered_dataframe.info()\n",
    "\n",
    "filtered_dataframe[filtered_dataframe.columns.difference(['Precip Type'])] = StandardScaler().fit_transform(filtered_dataframe[filtered_dataframe.columns.difference(['Precip Type'])])\n",
    "y2 = dataframe['Precip Type']\n",
    "X2 = dataframe[filtered_dataframe.columns.difference(['Precip Type'])]\n",
    "X2 =scaler.fit_transform(X2)\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=3)\n",
    "X2 = pca.fit_transform(X2)\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split ( X2, y2, test_size=0.2, stratify=filtered_dataframe['Precip Type'], random_state = 13)\n",
    "# Train a logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af956761a486e713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "y_pred_log= log_reg.predict(X2_test)\n",
    "\n",
    "acc = accuracy_score(y2_test, y_pred_log)\n",
    "pres = precision_score(y2_test, y_pred_log)\n",
    "reacll = recall_score(y2_test, y_pred_log)\n",
    "f1 = f1_score(y2_test, y_pred_log)\n",
    "\n",
    "print(f\"Accuracy: {acc:.5f}\")\n",
    "print(f\"Precision: {pres:.5f}\")\n",
    "print(f\"Recall: {reacll:.5f}\")\n",
    "print(f\"F1 Score: {f1:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e348c6f1a366fa19",
   "metadata": {},
   "source": [
    " 4) Apply L1 regulariser on the logistic regression model developed using the same train and test data used in Q3 and calculate performance of the new model. Compare performance of this model with the performance reported in Q3. Explain the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3c445fcbd58189",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_f1 = LogisticRegression(penalty='l1', solver='saga')\n",
    "log_reg_f1.fit(logX2_train, y2_train)\n",
    "y_pred_log_f1= log_reg_f1.predict(X2_test)\n",
    "\n",
    "acc_l1 = accuracy_score(y2_test, y_pred_log_f1)\n",
    "pres_l1 = precision_score(y2_test, y_pred_log_f1)\n",
    "reacll_l1 = recall_score(y2_test, y_pred_log_f1)\n",
    "f1_l1 = f1_score(y2_test, y_pred_log_f1)\n",
    "\n",
    "print(f\"Accuracy: {acc_l1:.5f}\")\n",
    "print(f\"Precision: {pres_l1:.5f}\")\n",
    "print(f\"Recall: {reacll_l1:.5f}\")\n",
    "print(f\"F1 Score: {f1_l1:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37428fc50851a74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
