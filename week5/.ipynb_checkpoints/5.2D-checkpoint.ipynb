{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "764312d27b178944",
   "metadata": {},
   "source": [
    "# 1) What is the mechanism used by the Voting Classifier to aggregate predictions from multiple base models and their differences? Explain with suitable example. If predictions conflict among the base models, what strategies can be employed to resolve the conflicts and make more reliable final predictions in the Voting Classifier? "
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b118eb47908d740",
   "metadata": {},
   "source": [
    "majority vote (hard voting) or averaging probabilities (soft voting).\n",
    "majority vote: Uses the mode of the predictions from base models\n",
    "averaging probabilities: Averages the probability estimates of the classifiers\n",
    "\n",
    "For conflicting predictions:\n",
    "Increasing Diversity: Different models or data subsets improve ensemble performance\n",
    "Weights: Classifiers can have weights based on performance\n",
    "Meta-Learners: Another model (meta-learner) is trained on the predictions of base classifiers\n",
    "\n",
    "Refs:\n",
    "\n",
    "Scikit-learn, (n.d.). 'Ensemble methods'. Scikit-learn Documentation. Available at: https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier [Accessed on: 12 August 2023].\n",
    "StatQuest with Josh Starmer, (n.d.). 'Ensemble Learning, Clearly Explained!'. YouTube. Available at: https://www.youtube.com/watch?v=Un9zObFjBH0 [Accessed on: 12 August 2023].\n",
    "Analytics Vidhya, (2015). 'A Complete Guide to Ensemble Learning'. Analytics Vidhya Blog. Available at: https://www.analyticsvidhya.com/blog/2015/08/introduction-ensemble-learning/ [Accessed on: 12 August 2023].\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe53410dd20e64cb",
   "metadata": {},
   "source": [
    "# 2) Prove that Elastic net can be used as either LASSO or Ridge regulariser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d911e8c33eca88",
   "metadata": {},
   "source": [
    "Elastic Net regularization is a linear combination of L1 and L2 regularization. Its objective function can be formulated as:\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\mathrm{MSE}(\\theta) + r \\alpha \\sum_{i=1}^{n} |\\theta_i| + \\frac{1-r}{2} \\alpha \\sum_{i=1}^{n} \\theta_i^2\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ J(\\theta) $ is the cost function.\n",
    "- $\\mathrm{MSE}(\\theta)$ stands for the Mean Squared Error.\n",
    "- $\\alpha$ is the regularization strength, equivalent to $\\lambda$ in some formulations.\n",
    "- $r$ is the mixing parameter between the L1 (LASSO) and L2 (Ridge) penalties. $r$ lies in the range [0,1].\n",
    "- $\\theta$ represents the parameter vector, and the summation runs over all its components.\n",
    "\n",
    "The two terms added to the MSE represent the L1 and L2 penalties:\n",
    "\n",
    "1. $ r \\alpha \\sum_{i=1}^{n} |\\theta_i| $ is the L1 penalty (LASSO). Elastic Net behaves as LASSO with a regularization strength of $\\alpha$ when $r = 1$.\n",
    "2. $ \\frac{1-r}{2} \\alpha \\sum_{i=1}^{n} \\theta_i^2 $ is the L2 penalty (Ridge). Elastic Net behaves as Ridge regression with a regularization strength of $\\alpha$ when $r = 0$.\n",
    "\n",
    "Based on the mixing parameter $r$:\n",
    "- When $r = 1$, the Elastic Net objective becomes:\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\mathrm{MSE}(\\theta) + \\alpha \\sum_{i=1}^{n} |\\theta_i|\n",
    "$$\n",
    "\n",
    "This is essentially the cost function for LASSO regression.\n",
    "\n",
    "- When $r = 0$, the Elastic Net objective becomes:\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\mathrm{MSE}(\\theta) + \\frac{1}{2} \\alpha \\sum_{i=1}^{n} \\theta_i^2\n",
    "$$\n",
    "\n",
    "This corresponds to the cost function for Ridge regression.\n",
    "\n",
    "Thus, by varying the parameter $r$, Elastic Net can be tailored to act as either LASSO (for $r = 1$) or Ridge (for $r = 0$) regularization.\n",
    "\n",
    "Reference:\n",
    "towards data science, (n.d.). 'Ridge, LASSO, and ElasticNet Regression'. Available at: https://towardsdatascience.com/ridge-lasso-and-elasticnet-regression-b1f9c00ea3a3 [Accessed on: 14 August 2023].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f6d0f3e2e1702c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d91d96b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94cb6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
