{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-09-18T09:57:09.487675Z",
     "end_time": "2023-09-18T09:57:09.541083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n0  2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n1  9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n2  8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n3  0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n4  3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n\n         p4        g1        g2        g3        g4      stab     stabf  \n0 -1.723086  0.650456  0.859578  0.887445  0.958034  0.055347  unstable  \n1 -1.255012  0.413441  0.862414  0.562139  0.781760 -0.005957    stable  \n2 -0.920492  0.163041  0.766689  0.839444  0.109853  0.003471  unstable  \n3 -0.997374  0.446209  0.976744  0.929381  0.362718  0.028871  unstable  \n4 -0.554305  0.797110  0.455450  0.656947  0.820923  0.049860  unstable  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tau1</th>\n      <th>tau2</th>\n      <th>tau3</th>\n      <th>tau4</th>\n      <th>p1</th>\n      <th>p2</th>\n      <th>p3</th>\n      <th>p4</th>\n      <th>g1</th>\n      <th>g2</th>\n      <th>g3</th>\n      <th>g4</th>\n      <th>stab</th>\n      <th>stabf</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.959060</td>\n      <td>3.079885</td>\n      <td>8.381025</td>\n      <td>9.780754</td>\n      <td>3.763085</td>\n      <td>-0.782604</td>\n      <td>-1.257395</td>\n      <td>-1.723086</td>\n      <td>0.650456</td>\n      <td>0.859578</td>\n      <td>0.887445</td>\n      <td>0.958034</td>\n      <td>0.055347</td>\n      <td>unstable</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9.304097</td>\n      <td>4.902524</td>\n      <td>3.047541</td>\n      <td>1.369357</td>\n      <td>5.067812</td>\n      <td>-1.940058</td>\n      <td>-1.872742</td>\n      <td>-1.255012</td>\n      <td>0.413441</td>\n      <td>0.862414</td>\n      <td>0.562139</td>\n      <td>0.781760</td>\n      <td>-0.005957</td>\n      <td>stable</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8.971707</td>\n      <td>8.848428</td>\n      <td>3.046479</td>\n      <td>1.214518</td>\n      <td>3.405158</td>\n      <td>-1.207456</td>\n      <td>-1.277210</td>\n      <td>-0.920492</td>\n      <td>0.163041</td>\n      <td>0.766689</td>\n      <td>0.839444</td>\n      <td>0.109853</td>\n      <td>0.003471</td>\n      <td>unstable</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.716415</td>\n      <td>7.669600</td>\n      <td>4.486641</td>\n      <td>2.340563</td>\n      <td>3.963791</td>\n      <td>-1.027473</td>\n      <td>-1.938944</td>\n      <td>-0.997374</td>\n      <td>0.446209</td>\n      <td>0.976744</td>\n      <td>0.929381</td>\n      <td>0.362718</td>\n      <td>0.028871</td>\n      <td>unstable</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.134112</td>\n      <td>7.608772</td>\n      <td>4.943759</td>\n      <td>9.857573</td>\n      <td>3.525811</td>\n      <td>-1.125531</td>\n      <td>-1.845975</td>\n      <td>-0.554305</td>\n      <td>0.797110</td>\n      <td>0.455450</td>\n      <td>0.656947</td>\n      <td>0.820923</td>\n      <td>0.049860</td>\n      <td>unstable</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"Data_for_UCI_named.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   tau1    10000 non-null  float64\n",
      " 1   tau2    10000 non-null  float64\n",
      " 2   tau3    10000 non-null  float64\n",
      " 3   tau4    10000 non-null  float64\n",
      " 4   p1      10000 non-null  float64\n",
      " 5   p2      10000 non-null  float64\n",
      " 6   p3      10000 non-null  float64\n",
      " 7   p4      10000 non-null  float64\n",
      " 8   g1      10000 non-null  float64\n",
      " 9   g2      10000 non-null  float64\n",
      " 10  g3      10000 non-null  float64\n",
      " 11  g4      10000 non-null  float64\n",
      " 12  stab    10000 non-null  float64\n",
      " 13  stabf   10000 non-null  object \n",
      "dtypes: float64(13), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-18T09:57:39.607536Z",
     "end_time": "2023-09-18T09:57:39.622430Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "0    unstable\n1      stable\n2    unstable\n3    unstable\n4    unstable\nName: stabf, dtype: object"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_frame = dataset[\"stabf\"]\n",
    "target_frame.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-18T09:58:40.291767Z",
     "end_time": "2023-09-18T09:58:40.302122Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n0  2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n1  9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n2  8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n3  0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n4  3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n\n         p4        g1        g2        g3        g4      stab  \n0 -1.723086  0.650456  0.859578  0.887445  0.958034  0.055347  \n1 -1.255012  0.413441  0.862414  0.562139  0.781760 -0.005957  \n2 -0.920492  0.163041  0.766689  0.839444  0.109853  0.003471  \n3 -0.997374  0.446209  0.976744  0.929381  0.362718  0.028871  \n4 -0.554305  0.797110  0.455450  0.656947  0.820923  0.049860  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tau1</th>\n      <th>tau2</th>\n      <th>tau3</th>\n      <th>tau4</th>\n      <th>p1</th>\n      <th>p2</th>\n      <th>p3</th>\n      <th>p4</th>\n      <th>g1</th>\n      <th>g2</th>\n      <th>g3</th>\n      <th>g4</th>\n      <th>stab</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.959060</td>\n      <td>3.079885</td>\n      <td>8.381025</td>\n      <td>9.780754</td>\n      <td>3.763085</td>\n      <td>-0.782604</td>\n      <td>-1.257395</td>\n      <td>-1.723086</td>\n      <td>0.650456</td>\n      <td>0.859578</td>\n      <td>0.887445</td>\n      <td>0.958034</td>\n      <td>0.055347</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9.304097</td>\n      <td>4.902524</td>\n      <td>3.047541</td>\n      <td>1.369357</td>\n      <td>5.067812</td>\n      <td>-1.940058</td>\n      <td>-1.872742</td>\n      <td>-1.255012</td>\n      <td>0.413441</td>\n      <td>0.862414</td>\n      <td>0.562139</td>\n      <td>0.781760</td>\n      <td>-0.005957</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8.971707</td>\n      <td>8.848428</td>\n      <td>3.046479</td>\n      <td>1.214518</td>\n      <td>3.405158</td>\n      <td>-1.207456</td>\n      <td>-1.277210</td>\n      <td>-0.920492</td>\n      <td>0.163041</td>\n      <td>0.766689</td>\n      <td>0.839444</td>\n      <td>0.109853</td>\n      <td>0.003471</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.716415</td>\n      <td>7.669600</td>\n      <td>4.486641</td>\n      <td>2.340563</td>\n      <td>3.963791</td>\n      <td>-1.027473</td>\n      <td>-1.938944</td>\n      <td>-0.997374</td>\n      <td>0.446209</td>\n      <td>0.976744</td>\n      <td>0.929381</td>\n      <td>0.362718</td>\n      <td>0.028871</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.134112</td>\n      <td>7.608772</td>\n      <td>4.943759</td>\n      <td>9.857573</td>\n      <td>3.525811</td>\n      <td>-1.125531</td>\n      <td>-1.845975</td>\n      <td>-0.554305</td>\n      <td>0.797110</td>\n      <td>0.455450</td>\n      <td>0.656947</td>\n      <td>0.820923</td>\n      <td>0.049860</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.drop(columns='stabf',axis=1, inplace=True)\n",
    "dataset.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-18T09:59:44.722784Z",
     "end_time": "2023-09-18T09:59:44.729364Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n0 -0.835374 -0.791317  1.141704  1.652103  0.017397  1.079405 -0.017078   \n1  1.478297 -0.126705 -0.803111 -1.415043  1.752124 -1.593619 -1.438158   \n2  1.357093  1.312140 -0.803499 -1.471504 -0.458492  0.098253 -0.062840   \n3 -1.653138  0.882289 -0.278354 -1.060901  0.284250  0.513904 -1.591046   \n4 -0.771543  0.860108 -0.111670  1.680114 -0.298075  0.287450 -1.376343   \n\n         p4        g1        g2        g3        g4      stab  \n0 -1.092545  0.457467  1.220013  1.321628  1.579026  1.073120  \n1 -0.011575 -0.406791  1.230354  0.135424  0.936256 -0.587487  \n2  0.760963 -1.319852  0.881299  1.146596 -1.513802 -0.332095  \n3  0.583414 -0.287304  1.647250  1.474543 -0.591750  0.355922  \n4  1.606636  0.992226 -0.253610  0.481133  1.079063  0.924487  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tau1</th>\n      <th>tau2</th>\n      <th>tau3</th>\n      <th>tau4</th>\n      <th>p1</th>\n      <th>p2</th>\n      <th>p3</th>\n      <th>p4</th>\n      <th>g1</th>\n      <th>g2</th>\n      <th>g3</th>\n      <th>g4</th>\n      <th>stab</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.835374</td>\n      <td>-0.791317</td>\n      <td>1.141704</td>\n      <td>1.652103</td>\n      <td>0.017397</td>\n      <td>1.079405</td>\n      <td>-0.017078</td>\n      <td>-1.092545</td>\n      <td>0.457467</td>\n      <td>1.220013</td>\n      <td>1.321628</td>\n      <td>1.579026</td>\n      <td>1.073120</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.478297</td>\n      <td>-0.126705</td>\n      <td>-0.803111</td>\n      <td>-1.415043</td>\n      <td>1.752124</td>\n      <td>-1.593619</td>\n      <td>-1.438158</td>\n      <td>-0.011575</td>\n      <td>-0.406791</td>\n      <td>1.230354</td>\n      <td>0.135424</td>\n      <td>0.936256</td>\n      <td>-0.587487</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.357093</td>\n      <td>1.312140</td>\n      <td>-0.803499</td>\n      <td>-1.471504</td>\n      <td>-0.458492</td>\n      <td>0.098253</td>\n      <td>-0.062840</td>\n      <td>0.760963</td>\n      <td>-1.319852</td>\n      <td>0.881299</td>\n      <td>1.146596</td>\n      <td>-1.513802</td>\n      <td>-0.332095</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.653138</td>\n      <td>0.882289</td>\n      <td>-0.278354</td>\n      <td>-1.060901</td>\n      <td>0.284250</td>\n      <td>0.513904</td>\n      <td>-1.591046</td>\n      <td>0.583414</td>\n      <td>-0.287304</td>\n      <td>1.647250</td>\n      <td>1.474543</td>\n      <td>-0.591750</td>\n      <td>0.355922</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.771543</td>\n      <td>0.860108</td>\n      <td>-0.111670</td>\n      <td>1.680114</td>\n      <td>-0.298075</td>\n      <td>0.287450</td>\n      <td>-1.376343</td>\n      <td>1.606636</td>\n      <td>0.992226</td>\n      <td>-0.253610</td>\n      <td>0.481133</td>\n      <td>1.079063</td>\n      <td>0.924487</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standardScaler = StandardScaler()\n",
    "standardScaler.fit(dataset)\n",
    "scaled_dataset = pd.DataFrame(standardScaler.transform(dataset), columns=dataset.columns.values)\n",
    "scaled_dataset.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-18T10:01:38.734156Z",
     "end_time": "2023-09-18T10:01:39.553999Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1) Download Electrical Grid Stability Simulated Datadatasets. Classify \"Electrical Grid Stability Simulated Data\" classes using KNN. Use the same data splitting and performance metrics that you have used in previous week (week 7, Q-2). Report your findings including comparison of results with week 7"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, f1_score\n",
    "## Same method used in Week 7 Exercise.\n",
    "def print_model_metrics(true_labels, predicted_labels):\n",
    "    # Calculate metrics for classification problems\n",
    "    acc = accuracy_score(true_labels, predicted_labels)\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "    prec = precision_score(true_labels, predicted_labels, average='macro')\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='macro') # for multiclass problems.,→ Use 'binary' for binary problems\n",
    "    # Print metrics\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "    print(\"\\nPrecision:\", prec)\n",
    "    print(\"\\nF1 Score:\", f1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-18T12:49:12.050999Z",
     "end_time": "2023-09-18T12:49:12.915309Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I am Also assuming we should also do the PCA as in exercise 7 to be able to properly compare the results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "pca=PCA(n_components=3)\n",
    "\n",
    "\n",
    "principal_components = pca.fit_transform(scaled_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-18T12:53:40.792049Z",
     "end_time": "2023-09-18T12:53:41.695053Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9025\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 595  110]\n",
      " [  85 1210]]\n",
      "\n",
      "Precision: 0.8958333333333333\n",
      "\n",
      "F1 Score: 0.8923179932491665\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split ( principal_components, target_frame, test_size=0.2 )\n",
    "classifier = KNeighborsClassifier().fit(X_train,y_train.values.ravel())\n",
    "predicted = classifier.predict(X_test)\n",
    "print_model_metrics(y_test, predicted)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-18T13:01:53.704407Z",
     "end_time": "2023-09-18T13:01:54.006880Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In our results, calculating the result of KNN Classification with DEFAULT HYPERPARAMETERS, we had an accuracy of .9025 vs .909 of Week's 7 resut.\n",
    "Our F1 Score = .892 vs .897 and Our precision was .89 vs .92 from last week. Our results also show a little bit of mixed results comparing the confusion matrix, 1210 vs 1250 true positives, 595 vs 568 true negatives, 110 vs 151 false positives and 85 vs 31 false negatives. Overall, last week's algorithm was slightly better to the given problem, even though the difference did not show to be too big. The current model still show a slightly better metric to avoid false positives though.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2)Load Electrical Grid Stability Simulated Data and create classification model using DT algorithm using 50-50% and 80-20% data splitting methods. Compare performances of these two models and explain impact of difference in data splitting on the performances of the model.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8805\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 591  114]\n",
      " [ 125 1170]]\n",
      "\n",
      "Precision: 0.868316973842218\n",
      "\n",
      "F1 Score: 0.8695685036860541\n"
     ]
    }
   ],
   "source": [
    "##Data Already loaded under dataset. Previous distribution was 80-20: Running tree:\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "treeclassifier = DecisionTreeClassifier( random_state=13)\n",
    "treeclassifier.fit(X_train,y_train.values.ravel())\n",
    "tree_predicted = treeclassifier.predict(X_test)\n",
    "print_model_metrics(y_test, tree_predicted)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-18T19:14:33.980787Z",
     "end_time": "2023-09-18T19:14:34.430051Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9744\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1777   64]\n",
      " [  64 3095]]\n",
      "\n",
      "Precision: 0.9724883544063941\n",
      "\n",
      "F1 Score: 0.9724883544063941\n"
     ]
    }
   ],
   "source": [
    "X_train_50, X_test_50, y_train_50, y_test_50 = train_test_split ( principal_components, target_frame, test_size=0.5)\n",
    "treeclassifier_50 = DecisionTreeClassifier( random_state=13)\n",
    "treeclassifier_50.fit(X_train_50,y_train_50.values.ravel())\n",
    "tree_predicted_50 = treeclassifier.predict(X_test_50)\n",
    "print_model_metrics(y_test_50, tree_predicted_50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-18T19:18:52.386129Z",
     "end_time": "2023-09-18T19:18:52.504211Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In our result we can infer that all the metrics were superior in the 50/50 split. That is a strong indication that if we do a 80/20 split of tha data we are incurring into overfitting, degrading the overall result of our predictions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3) Create two more KNN-based classification models using the dataset used in Q1 by varying distance metrics such as using  cityblock and manhattan. Report the performances of the developed models including Q1 and explain the similarity or differences if any."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9015\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 596  109]\n",
      " [  88 1207]]\n",
      "\n",
      "Precision: 0.8942591407597007\n",
      "\n",
      "F1 Score: 0.8913606635712727\n",
      "Accuracy: 0.9015\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 596  109]\n",
      " [  88 1207]]\n",
      "\n",
      "Precision: 0.8942591407597007\n",
      "\n",
      "F1 Score: 0.8913606635712727\n"
     ]
    }
   ],
   "source": [
    "classifier_manhattan = KNeighborsClassifier(metric=\"manhattan\").fit(X_train,y_train.values.ravel())\n",
    "\n",
    "classifier_cityblock = KNeighborsClassifier(metric=\"cityblock\").fit(X_train,y_train.values.ravel())\n",
    "\n",
    "predicted_manhattan = classifier_manhattan.predict(X_test)\n",
    "predicted_city = classifier_cityblock.predict(X_test)\n",
    "\n",
    "print_model_metrics(y_test, predicted_manhattan)\n",
    "print_model_metrics(y_test, predicted_city)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-18T19:42:26.091386Z",
     "end_time": "2023-09-18T19:42:26.290582Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As a result, the scores were quite similar in the Q1 we got:\n",
    "\n",
    "Accuracy: 0.9025\n",
    "Confusion Matrix:\n",
    " [[ 595  110]\n",
    " [  85 1210]]\n",
    "Precision: 0.8958333333333333\n",
    "F1 Score: 0.8923179932491665\n",
    "\n",
    "for BOTH the manhattan and the cityblock metrics we got:\n",
    "Accuracy: 0.9015\n",
    "\n",
    "Confusion Matrix:\n",
    " [[ 596  109]\n",
    " [  88 1207]]\n",
    "\n",
    "Precision: 0.8942591407597007\n",
    "\n",
    "F1 Score: 0.8913606635712727\n",
    "The result of manhattan and cityblock were identical. upon further research, i found reference (https://stackoverflow.com/questions/37303146/distance-metrics-in-scikit-learn) that both the metrics actually point to the same distance calculation implementation, being in fact, the same. As a conclusion, the distance calculation methods used in the model, in this case did not have a major impact on the predictions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
